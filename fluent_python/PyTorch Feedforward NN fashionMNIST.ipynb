{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "surprised-bidder",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# designing and implementing feedforward NN in PyTorch to classify fashionMNIST\n",
    "\n",
    "# accuracy = 35%\n",
    "\n",
    "\n",
    "# to use your own images with pytorch you might need to put them in their own class, as set out:\n",
    "# https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "# under 'Creating a Custom Dataset for your files'\n",
    "\n",
    "\n",
    "\n",
    "# transforming data (eg: to normalise)\n",
    "# https://pytorch.org/tutorials/beginner/basics/transforms_tutorial.html\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# arguing that fashionMNIST is a better choice than MNIST:\n",
    "# https://github.com/zalandoresearch/fashion-mnists\n",
    "\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import ToTensor    # ToTensor converts PIL image or nparray to FloatTensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "confused-relations",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4514, 0.5145, 0.1621, 0.5151, 0.9154, 0.7347, 0.6770, 0.1456, 0.8674,\n",
      "         0.6700]])\n",
      "tensor([[0.0866, 0.0922, 0.0648, 0.0923, 0.1377, 0.1150, 0.1085, 0.0638, 0.1313,\n",
      "         0.1078]])\n",
      "tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 10)\n",
    "print(X)                      # random vector of 10 values, which could be NN outputs for 10-class classifier\n",
    "print(nn.Softmax(dim=1)(X))   # may wish to put outputs of NN through softmax\n",
    "print(torch.sum(nn.Softmax(dim=1)(X)))   # showing softmax outputs sum to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "colonial-north",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2875255c6f4c44b282cf86bb21ce5013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=26421880.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db66f500a4a407fb65deafb3a6785e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=29515.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5be97b37d2c45aaa839be1ede510539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4422102.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c43f3d7b784eb68d188965682dd87c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5148.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torchvision/datasets/mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "certified-throw",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "compatible-warning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# see first 3 images in training data set\n",
    "plt.subplot(1,3,1)    \n",
    "plt.imshow(training_data[0][0][0, :, :], cmap=\"gray\")\n",
    "plt.subplot(1,3,2)    \n",
    "plt.imshow(training_data[1][0][0, :, :], cmap=\"gray\")\n",
    "plt.subplot(1,3,3)    \n",
    "plt.imshow(training_data[2][0][0, :, :], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "wired-andrew",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
      "Shape of y:  torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64 # minibatch size\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size) # creates python iterable over dataset\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "satisfied-junction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(   # container of sequential operations\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"flatten input and return 10 values at end of sequence, as there are 10 classes\"\"\"\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x) \n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "indirect-knowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()     # chosing loss function \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)  # set optimiser with learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aware-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    \"\"\"Single training epoch, looping through mini-batches as set in dataloader obj\"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()  # setting weights to zero - not sure if doing this on every epoch or not\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:     # printing diagnostics on every 100th batch\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "usual-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    \"\"\"test performance of model on test dataset\"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()    # puts the model into eval model (instead of train); a form of switch\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():    # no_grad disables gradient calculation\n",
    "                               # anytime we're applying the model, put it within no_grad so no updates made\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)         \n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches   # shorthand for: test_loss = test_loss / num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "sapphire-branch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.175393  [    0/60000]\n",
      "loss: 2.188902  [ 6400/60000]\n",
      "loss: 2.164962  [12800/60000]\n",
      "loss: 2.195203  [19200/60000]\n",
      "loss: 2.164782  [25600/60000]\n",
      "loss: 2.152572  [32000/60000]\n",
      "loss: 2.183286  [38400/60000]\n",
      "loss: 2.161990  [44800/60000]\n",
      "loss: 2.178070  [51200/60000]\n",
      "loss: 2.157706  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 35.3%, Avg loss: 2.167707 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.175393  [    0/60000]\n",
      "loss: 2.188902  [ 6400/60000]\n",
      "loss: 2.164962  [12800/60000]\n",
      "loss: 2.195203  [19200/60000]\n",
      "loss: 2.164782  [25600/60000]\n",
      "loss: 2.152572  [32000/60000]\n",
      "loss: 2.183286  [38400/60000]\n",
      "loss: 2.161990  [44800/60000]\n",
      "loss: 2.178070  [51200/60000]\n",
      "loss: 2.157706  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 35.3%, Avg loss: 2.167707 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.175393  [    0/60000]\n",
      "loss: 2.188902  [ 6400/60000]\n",
      "loss: 2.164962  [12800/60000]\n",
      "loss: 2.195203  [19200/60000]\n",
      "loss: 2.164782  [25600/60000]\n",
      "loss: 2.152572  [32000/60000]\n",
      "loss: 2.183286  [38400/60000]\n",
      "loss: 2.161990  [44800/60000]\n",
      "loss: 2.178070  [51200/60000]\n",
      "loss: 2.157706  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 35.3%, Avg loss: 2.167707 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.175393  [    0/60000]\n",
      "loss: 2.188902  [ 6400/60000]\n",
      "loss: 2.164962  [12800/60000]\n",
      "loss: 2.195203  [19200/60000]\n",
      "loss: 2.164782  [25600/60000]\n",
      "loss: 2.152572  [32000/60000]\n",
      "loss: 2.183286  [38400/60000]\n",
      "loss: 2.161990  [44800/60000]\n",
      "loss: 2.178070  [51200/60000]\n",
      "loss: 2.157706  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 35.3%, Avg loss: 2.167707 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.175393  [    0/60000]\n",
      "loss: 2.188902  [ 6400/60000]\n",
      "loss: 2.164962  [12800/60000]\n",
      "loss: 2.195203  [19200/60000]\n",
      "loss: 2.164782  [25600/60000]\n",
      "loss: 2.152572  [32000/60000]\n",
      "loss: 2.183286  [38400/60000]\n",
      "loss: 2.161990  [44800/60000]\n",
      "loss: 2.178070  [51200/60000]\n",
      "loss: 2.157706  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 35.3%, Avg loss: 2.167707 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "### training process\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)   \n",
    "    test(test_dataloader, model, loss_fn)   # tells you how it's doing\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "comparative-static",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")  # saving model\n",
    "\n",
    "\n",
    "# loading model involves initialising a network and loading the .pth model state into it\n",
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "foreign-relief",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "9\n",
      "tensor([[0.1031, 0.0832, 0.1421, 0.0797, 0.1332, 0.0744, 0.1154, 0.0743, 0.0997,\n",
      "         0.0950]])\n",
      "class with highest prediction: Pullover\n",
      "Predicted: \"Pullover\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "# making a prediction for a single data point\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()    # eval mode is also prediction mode\n",
    "x, y = test_data[1][0], test_data[0][1]\n",
    "print(x.shape)\n",
    "print(y)\n",
    "softmax = nn.Softmax(dim=1)  # defining softmax for our uses\n",
    "with torch.no_grad():    # anytime we're applying the model, put it within no_grad so no updates made\n",
    "    pred = model(x)\n",
    "    pred = softmax(pred)   # effectively rescales to sum to 1 (tho not necessary to pick the highest scorer)\n",
    "    print(pred)\n",
    "    print('class with highest prediction: ' + str(classes[pred[0].argmax(0)]))\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-sender",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "robust-workshop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure:  NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0212,  0.0024,  0.0211,  ...,  0.0309, -0.0109,  0.0190],\n",
      "        [ 0.0290,  0.0011, -0.0206,  ..., -0.0036, -0.0340, -0.0131]],\n",
      "       grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([ 0.0245, -0.0284], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0139, -0.0065, -0.0233,  ..., -0.0002,  0.0407,  0.0092],\n",
      "        [-0.0320,  0.0230, -0.0432,  ...,  0.0001, -0.0395,  0.0131]],\n",
      "       grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0321, -0.0269], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0083, -0.0294,  0.0107,  ..., -0.0283, -0.0168, -0.0171],\n",
      "        [-0.0251,  0.0092,  0.0409,  ..., -0.0119,  0.0435,  0.0394]],\n",
      "       grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([0.0053, 0.0304], grad_fn=<SliceBackward>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view weights for each layer\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
