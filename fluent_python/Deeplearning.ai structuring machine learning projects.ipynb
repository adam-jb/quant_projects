{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caring-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# notes from week 1 of https://www.coursera.org/learn/machine-learning-projects/home/week/1\n",
    "\n",
    "# orthogonalisation: each thing only does one thing, not affecting the other things (is orthogonal to other things)\n",
    "\n",
    "\n",
    "### things to improve performance at each stage:\n",
    "# if bad on train set: better optimiser, bigger network, train longer, search for better hyperparams\n",
    "# if bad on dev set: more train data, regularise, data augmentation\n",
    "# if bad on test set: bigger dev set (so can pick up performance issues there)\n",
    "# if bad on implementation in real world: bigger dev set or change cost function\n",
    "\n",
    "### ideally do actions to have an effect on just one of the stages of the above (orthogonalisation!)\n",
    "\n",
    "\n",
    "# when training: best to use a single evaluation metric that combines everything you care about, eg: F1 Score\n",
    "\n",
    "\n",
    "# might want to maximise one metric within the bound of running time being below a certain value, in\n",
    "# such a case running time would be a 'satisficing' metric\n",
    "\n",
    "# another satisficing metric: maximise alexa accuracy while not having more than one false positive per 24 hrs\n",
    "\n",
    "\n",
    "# tho people leave out test set sometimes, suggests you include it alongside train and dev sets\n",
    "\n",
    "\n",
    "\n",
    "# if you know how people do on a task (eg: image classification), the difference between train set\n",
    "# error and error of humans doing the task, can be used as a metric for the \"avoidable bias\",\n",
    "# suggesting how much bias could theoretically be improved if trained model can get to human \n",
    "# level performance\n",
    "\n",
    "# Then difference between performance on train and dev sets as a metric for variance\n",
    "\n",
    "# error from human classifcation as a proxy for Bayes Error (ie, irreducible error)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes from week 2 of https://www.coursera.org/learn/machine-learning-projects/home/week/2:\n",
    "\n",
    "\n",
    "### to transfer pre-trained model:\n",
    "# reinitialise weights on output layer, and keep weights in all other layers constant\n",
    "# put new training data (eg: images of thing you care about) through model and train the output \n",
    "# layer's weights to get new weights for that\n",
    "# model should now be good for predicting your specific thing\n",
    "# if you have more data then you could retrain earlier layers too I think, could be a thing to try\n",
    "\n",
    "# another transfer approach might be to start with the trained-model's weights, and then keep\n",
    "# training the whole network on your new data (so the pre-trained weights provide a kind of \n",
    "# starting point). Not sure this is a thing that's actually done\n",
    "\n",
    "# transfer gives you the benefit of a pre-set network structure which you know works well for a \n",
    "# particular class of tasks (eg: recognising objects in images in general)\n",
    "\n",
    "\n",
    "# transfer learning makes sense when you have lots of data you can transfer from, and a \n",
    "# smaller dataset for the specific task\n",
    "\n",
    "\n",
    "# generic speech recognition network can be transferred to detect specific words (eg OK Google)\n",
    "# instead of retraining output layer weights, you might add an extra layer or two before the \n",
    "# output layer, instead of retraining the last few layers prior to the output layer: the view\n",
    "# suggests this is done for speech recognition transfer learning\n",
    "\n",
    "\n",
    "# more on transfer learning:\n",
    "# https://www.coursera.org/learn/machine-learning-projects/lecture/WNPap/transfer-learning\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Multi-task learning\n",
    "\n",
    "# could have an image recogniser that counts how many objects of different classes (eg: cat, dog, person, etc)\n",
    "# are in each image (or at least has a binary classification for which classes are present in each image)\n",
    "\n",
    "# eg in an image: if you have 5 classes, the output is a (5, 1) array of whether they are present or not\n",
    "# same loss is used as logistic output layer, putting all 5 values thru logistic loss func and summing, \n",
    "# rather than a single value (as a binary classification NN would do)\n",
    "# unlike softmax, this allows multiple values to be detected in one image\n",
    "\n",
    "# says it helps if you have a similar number of things of each class in the training set (I think\n",
    "# this is the meaning of below video around 9 minutes in)\n",
    "# https://www.coursera.org/learn/machine-learning-projects/lecture/l9zia/multi-task-learning\n",
    "\n",
    "# multitask learning tends to be used for computer vision\n",
    "# says it needs larger networks to do well\n",
    "\n",
    "# a single multitask network works better than separate networks to detect each individual class \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### for facial recognition, process is broken into two steps:\n",
    "# 1) detect face within larger image, and export just the face\n",
    "# 2) run facial recognition NN\n",
    "# more on this:\n",
    "# https://www.coursera.org/learn/machine-learning-projects/lecture/k0Klk/what-is-end-to-end-deep-learning\n",
    "\n",
    "# facial recognition works by taking two images and telling you whether they are the same person or not\n",
    "# presumably via some kind of similarity score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# can think of NNs as having two inputs:\n",
    "# raw data\n",
    "# manually created components\n",
    "### where training datasets are small, manually created components become more useful\n",
    "\n",
    "# if you use only raw data, this might be described as 'end-to-end' deep learning\n",
    "\n",
    "# more on when end-to-end DL is most appropriate:\n",
    "# https://www.coursera.org/learn/machine-learning-projects/lecture/H56eb/whether-to-use-end-to-end-deep-learning\n",
    "\n",
    "\n",
    "# more difficult tasks require more data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
